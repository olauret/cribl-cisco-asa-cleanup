output: default
groups:
  IF9Gmi:
    name: Drop and/or suppress
    description: Pick neither, either, or both. Adjust suppression options as required
    index: 4
  JE4Inc:
    name: Extract Fields
    index: 6
    description: Pull regex from asa_parse and extract the defined groups
    disabled: true
  498tsT:
    name: "[Optional] GeoIP Lookup"
    description: requires download and install of a GeoIP lookup DB (maxmind city level is
      a popular one)
    disabled: true
    index: 7
  sf9vO1:
    name: Output Options
    description: Pick either Splunk or ECS chained pipelines
    index: 8
    disabled: true
asyncFuncTimeout: 1000
functions:
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: Please see the README for how to use this pack
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: |
        Summary of work:
        * Extract the asa_code
        * If asa_code is in asa_drops.csv drop the event
        * Trim _raw up to the %ASA string
        * Extract fields for asa_codes în așa_parsing.csv
        * GeoIP lookup (requires MaxMind or other geoip db)
        * For selected codes, suppress logs (allow 1 event per some time window)
        * OUTPUT: send using Splunk-like fields, or send using ECS fields
  - id: eval
    filter: "true"
    disabled: null
    conf:
      add:
        - name: asa_code
          value: _raw.match(/%ASA-\S*-(\d+):/)[1]
    description: Extract the ASA code
  - id: eval
    filter: "!asa_code"
    disabled: false
    conf:
      add:
        - name: _no_matches
          value: "true"
    final: true
    description: If we can't match any ASA code, add no_matches and stop here
  - id: drop
    filter: C.Lookup('asa_drops.csv').match(asa_code)
    disabled: false
    conf: {}
    final: true
    groupId: IF9Gmi
    description: If the code is present in the asa_drops lookup, we drop the event
  - id: suppress
    filter: C.Lookup('asa_suppress.csv').match(asa_code)
    disabled: false
    conf:
      allow: 1
      suppressPeriodSec: 30
      dropEventsMode: true
      maxCacheSize: 50000
      cacheIdleTimeoutPeriods: 2
      numEventsIdleTimeoutTrigger: 10000
      keyExpr: asa_code
    description: 1 event per 30 seconds per asa_code allowed through for matching events
    groupId: IF9Gmi
  - id: eval
    filter: suppressCount
    disabled: true
    conf:
      add:
        - name: _raw
          value: "`${_raw} repeated=${suppressCount}`"
        - name: suppressCount
          value: undefined
    groupId: IF9Gmi
    description: "Optional: Append suppressed count to _raw, and drop suppressCount ITF"
  - id: eval
    filter: "true"
    disabled: false
    conf:
      add:
        - name: _raw
          value: _raw.replace(/.*?%ASA-/,'%ASA-')
        - name: product
          value: "'ASA'"
        - name: vendor
          value: "'Cisco'"
        - name: vendor_product
          value: "'Cisco ASA'"
    description: Trim everything leading up to the ASA code; add a few fields the Splunk TA
      adds
  - id: lookup
    filter: "true"
    disabled: true
    conf:
      matchMode: exact
      reloadPeriodSec: 60
      addToEvent: false
      inFields:
        - eventField: asa_code
          lookupField: asa_code
      ignoreCase: false
      file: asa_parsing.csv
      outFields:
        - lookupField: regex
          eventField: __regex
    groupId: JE4Inc
    description: Lookup regex for the ASA code
  - id: eval
    filter: __regex
    disabled: true
    conf:
      add:
        - name: groups
          value: _raw.match(__regex).groups
        - name: _no_matches
          value: groups == undefined
    groupId: JE4Inc
    description: Use resulting regex to extract fields, and clean up some
  - id: flatten
    filter: "! _no_matches"
    disabled: true
    conf:
      fields:
        - groups
      prefix: ""
      depth: 5
      delimiter: _
    groupId: JE4Inc
    description: flatten the matching groups
  - id: rename
    filter: "! _no_matches"
    disabled: true
    conf:
      wildcardDepth: 5
      baseFields: []
      renameExpr: "name.startsWith('groups_') ?
        name.replace('groups_','').replace(/_ALT$/,'').toLowerCase() : name"
    description: Correct the field names to trim groups_ from the start, and _ALT from the
      end
    groupId: JE4Inc
  - id: geoip
    filter: src_ip || dest_ip
    disabled: true
    conf:
      inField: src_ip
      outField: src_geo
      file: GeoLite2-City.mmdb
      additionalFields:
        - extraInField: dest_ip
          extraOutField: dest_geo
    groupId: 498tsT
  - id: eval
    filter: src_geo || dest_geo
    disabled: true
    conf:
      remove:
        - "*.names.de"
        - "*.names.es"
        - "*.names.fr"
        - "*.names.ja"
        - "*.names.pt-BR"
        - "*.names.ru"
        - "*.names.zh-CN"
        - "*.geoname_id"
        - "*.continent"
        - "*.postal"
        - "*.registered_country"
        - "*.subdivisions"
        - "*.country.names"
        - "*.location.metro_code"
        - "*.location.accuracy_radius"
        - "*.location.time_zone"
    groupId: 498tsT
  - id: flatten
    filter: src_geo || dest_geo
    disabled: true
    conf:
      fields:
        - src_geo
        - dest_geo
      prefix: ""
      depth: 5
      delimiter: _
    groupId: 498tsT
  - id: rename
    filter: src_geo || dest_geo
    disabled: true
    conf:
      wildcardDepth: 5
      renameExpr: name.replace(/([^_]+)_.*_([^_]+)/,"$1_$2").replace(/code$/, "country")
    groupId: 498tsT
  - id: chain
    filter: "true"
    disabled: true
    conf:
      processor: prep_for_splunk
    groupId: sf9vO1
    description: Sending to Splunk
  - id: chain
    filter: "true"
    disabled: true
    conf:
      processor: prep_for_ECS
    groupId: sf9vO1
    description: Sending to Elastic
